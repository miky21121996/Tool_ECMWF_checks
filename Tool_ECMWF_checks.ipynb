{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6e0e109-1d42-46bc-a66f-d14fd90b8e34",
   "metadata": {},
   "source": [
    "# Climatology Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d25d4b1-bda3-497b-9a3e-7746938e0bf5",
   "metadata": {},
   "source": [
    "The user can specify:\n",
    "- Path to ECMWF data (see structure of folders and files in the default path)\n",
    "- Output directory: where all the outputs will be saved\n",
    "- Start Date and End Date of Climatology Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "642b7edf-cb70-4fe3-b859-9e8ed54af11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c978e8d1-994e-4fa3-bb4c-9d48cad5b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data directory and the variables of interest\n",
    "data_dir = '/data/inputs/METOCEAN/historical/model/atmos/ECMWF/IFS_010/analysis/6h/netcdf'\n",
    "output_dir = '/work/cmcc/mg28621/out_ECMWF_Tool_Checks/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "variables = ['T2M', 'D2M', 'MSL', 'U10M', 'V10M', 'LSM']\n",
    "\n",
    "# Define the date range\n",
    "start_date = '2019-01-01'\n",
    "end_date = '2023-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b7648a0-1cff-4e5a-8811-aee3368c1615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date strings to datetime objects\n",
    "start_date_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "end_date_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "\n",
    "# Extract the year from the datetime objects\n",
    "start_year = start_date_dt.year\n",
    "end_year = end_date_dt.year\n",
    "\n",
    "# Create a list to store data for each variable\n",
    "data = {var: [] for var in variables}\n",
    "time_index = []\n",
    "\n",
    "# For the moment being these dates need to be excluded from from climatology calculation for all variables, due to Land Sea Mask Errors\n",
    "# If you decide to change the period and you are sure no issues exist, you can modify this line in: excluded_dates = pd.to_datetime([])\n",
    "excluded_dates = pd.to_datetime([\n",
    "    '2023-12-03 12:00', \n",
    "    '2023-11-01 06:00'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba3fa30-c8a5-4574-a53b-9173a2945c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each year and month to find the corresponding files\n",
    "for year in range(2019, 2024):\n",
    "    print(year)\n",
    "    for month in range(1, 13):\n",
    "        print(month)\n",
    "        if f'{year}-{month:02d}' > end_date[:7]:\n",
    "            break\n",
    "        if f'{year}-{month:02d}' < start_date[:7]:\n",
    "            continue\n",
    "        # Create the file pattern for the current month\n",
    "        file_pattern = os.path.join(data_dir, f'{year}/{month:02d}', '*MEDATL*.nc')\n",
    "        files = sorted(glob.glob(file_pattern))\n",
    "        \n",
    "        # Process each file\n",
    "        for file in files:\n",
    "            # Open the dataset\n",
    "            ds = xr.open_dataset(file)\n",
    "            \n",
    "            # Extract the time values\n",
    "            times = pd.to_datetime(ds['time'].values)\n",
    "            \n",
    "            # Filter out the excluded dates for all variables\n",
    "            valid_times = ~times.isin(excluded_dates)\n",
    "            times = times[valid_times]\n",
    "            \n",
    "            # Store data for valid times\n",
    "            for var in variables:\n",
    "                data[var].append(ds[var].values[valid_times])\n",
    "            time_index.extend(times)\n",
    "            \n",
    "            # Close the dataset\n",
    "            ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2cca34d-a765-4b6a-a063-b2a47aabe08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data into xarray datasets\n",
    "data_arrays = {var: xr.DataArray(np.concatenate(data[var], axis=0), coords=[time_index, ds['lat'].values, ds['lon'].values], dims=['time', 'lat', 'lon']) for var in variables}\n",
    "# Apply Land Sea Mask on variables\n",
    "for var in variables:\n",
    "    if var != 'LSM':\n",
    "        print(var)\n",
    "        data_arrays[var] = data_arrays[var] * np.logical_not(data_arrays['LSM'])\n",
    "        data_arrays[var] = data_arrays[var].where(np.logical_not(data_arrays['LSM']) !=0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5e4bd0c-d450-4642-a0e5-656057b77ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the moment being the bissextile years are considered as non-bissextile years\n",
    "\n",
    "time_da = xr.DataArray(time_index, dims='time')\n",
    "\n",
    "is_leap_year = time_da.dt.is_leap_year\n",
    "is_feb_29 = (time_da.dt.month == 2) & (time_da.dt.day == 29)\n",
    "valid_days = ~(is_leap_year & is_feb_29)\n",
    "\n",
    "valid_days = valid_days.values\n",
    "\n",
    "time_index_filtered = np.array(time_index)[valid_days]\n",
    "\n",
    "time_da_filtered = xr.DataArray(time_index_filtered, dims='time')\n",
    "\n",
    "leap_years = np.unique(time_da_filtered.dt.year[time_da_filtered.dt.is_leap_year])\n",
    "is_after_feb_29_leap_year = np.zeros(time_da_filtered.size, dtype=bool)\n",
    "for year in leap_years:\n",
    "    # Identify dates after February 29th for the current leap year\n",
    "    is_current_leap_year = (time_da_filtered.dt.year == year)\n",
    "    is_after_feb_29 = (time_da_filtered.dt.month > 2) | ((time_da_filtered.dt.month == 2) & (time_da_filtered.dt.day > 29))\n",
    "    # Combine conditions\n",
    "    is_after_feb_29_leap_year |= (is_current_leap_year & is_after_feb_29)\n",
    "\n",
    "time_da_corrected = time_da_filtered.copy()\n",
    "time_da_corrected.values[is_after_feb_29_leap_year] -= np.timedelta64(1, 'D')\n",
    "\n",
    "dayofyear = time_da_corrected.dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e852ef2-714a-4247-9163-1be4f9f0bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Med Sea limits\n",
    "lat_min, lat_max = 30, 46\n",
    "lon_min, lon_max = -6, 40.2\n",
    "\n",
    "# Filtering data only for Med Sea\n",
    "mediterranean_data_arrays = {\n",
    "    var: array.sel(lat=slice(lat_max, lat_min), lon=slice(lon_min, lon_max)) for var, array in data_arrays.items()\n",
    "}\n",
    "\n",
    "# Mask for Med Sea, excluded Atlantic ad in-land Lakes\n",
    "lat = mediterranean_data_arrays['LSM'].lat\n",
    "lon = mediterranean_data_arrays['LSM'].lon\n",
    "\n",
    "mask_atlantic = (lat >42 ) & (lon > -6) & (lon < 0)\n",
    "mask_inland_lakes = (lat > 37) & (lat < 40) & (lon > 27.8)\n",
    "\n",
    "total_mask = mask_atlantic | mask_inland_lakes\n",
    "\n",
    "# Apply mask to data\n",
    "for var in mediterranean_data_arrays:\n",
    "    mediterranean_data_arrays[var] = mediterranean_data_arrays[var].where(~total_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53287c2c-d480-44a3-b18b-d6d278b3b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of LSM sum time series\n",
    "filtered_lsm = mediterranean_data_arrays['LSM'].where(mediterranean_data_arrays['LSM'] != 1, np.nan)\n",
    "lsm_sum = filtered_lsm.where(filtered_lsm != False, 1).sum(dim=['lat', 'lon'])\n",
    "\n",
    "# Crea un plot della serie temporale\n",
    "plt.figure(figsize=(10, 5))\n",
    "lsm_sum.plot()\n",
    "plt.title('LSM sum time series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('LSM elements sum')\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(output_dir, f'mediterranean_LSM_sum_time_series_{start_year}_{end_year}.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed43058-43c1-4d7f-951d-1724a191cd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Group data by corrected dayofyear\n",
    "climatology_stats_mediterranean = {}\n",
    "for var, array in mediterranean_data_arrays.items():\n",
    "    daily = array.sel(time=time_da_filtered).groupby(dayofyear)\n",
    "    climatology_stats_mediterranean[var] = {\n",
    "        'mean': daily.mean(dim='time',skipna=True),\n",
    "        'std': daily.std(dim='time',skipna=True)\n",
    "#        'min': daily.min(dim='time',skipna=True), other method to compute clim_min and max as mean of annual maxs and mins\n",
    "#        'max': daily.max(dim='time',skipna=True) \n",
    "    }\n",
    "\n",
    "    # 1. Group data by year\n",
    "    yearly_grouped = array.sel(time=time_da_corrected).groupby('time.year')\n",
    "    \n",
    "    # 2. Inside each year, group by dayofyear and compute max for each day\n",
    "    yearly_max = yearly_grouped.map(lambda x: x.groupby('time.dayofyear').max(dim='time', skipna=True))\n",
    "    \n",
    "    # 3. Compute clim_max for each dayofyear\n",
    "    #climatology_stats_mediterranean[var]['max'] = yearly_max.mean(dim='year', skipna=True) # other method\n",
    "    climatology_stats_mediterranean[var]['max'] = yearly_max.max(dim='year', skipna=True)\n",
    "    \n",
    "    # Same for minimum\n",
    "    yearly_grouped = array.sel(time=time_da_corrected).groupby('time.year')\n",
    "    yearly_min = yearly_grouped.map(lambda x: x.groupby('time.dayofyear').min(dim='time', skipna=True))\n",
    "\n",
    "    #climatology_stats_mediterranean[var]['min'] = yearly_min.mean(dim='year', skipna=True) # altro metodo\n",
    "    climatology_stats_mediterranean[var]['min'] = yearly_min.min(dim='year', skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11e29c2f-a56c-43c5-becb-be63aa0467bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the climatology statistics to NetCDF files\n",
    "for var, stats in climatology_stats_mediterranean.items():\n",
    "    ds_climatology_mediterranean = xr.Dataset({\n",
    "        'mean': stats['mean'],\n",
    "        'std': stats['std'],\n",
    "        'min': stats['min'],\n",
    "        'max': stats['max']\n",
    "    })\n",
    "    ds_climatology_mediterranean.to_netcdf(os.path.join(output_dir, f'{var}_climatology_mediterranean.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9347cb50-c85e-4c92-90b2-40650ad888df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_statistics_mediterranean(start_date_dt, end_date_dt, stat_name, stat_data, output_file):\n",
    "    units = {\n",
    "        'T2M': 'K',\n",
    "        'D2M': 'K',\n",
    "        'MSL': 'Pa',\n",
    "        'U10M': 'm/s',\n",
    "        'V10M': 'm/s'\n",
    "    }\n",
    "    fig, axes = plt.subplots(len(units.keys()), 1, figsize=(15, 20), sharex=True)\n",
    "    fig.suptitle(f'Spatially Averaged Climatological Daily {stat_name.capitalize()} over the Mediterranean frim {start_date_dt.strftime(\"%Y-%m.%d\")} to {end_date_dt.strftime(\"%Y-%m-%d\")}', fontsize=20)\n",
    "    for i, var in enumerate(units.keys()):\n",
    "        day_range = pd.date_range(start=start_date_dt.replace(day=1).strftime('%Y-%m-%d'), periods=365)\n",
    "        axes[i].plot(day_range, stat_data[var], label=f'{var} {stat_name.capitalize()}', color='blue')\n",
    "        axes[i].set_title(f'{var} {stat_name.capitalize()}',fontsize=20)\n",
    "        axes[i].set_ylabel(f'{var} ({units[var]})',fontsize=20)\n",
    "        axes[i].legend(prop={'size': 6})\n",
    "        axes[i].xaxis.set_major_formatter(mdates.DateFormatter('%b'))\n",
    "        axes[i].xaxis.set_major_locator(mdates.MonthLocator())\n",
    "\n",
    "    plt.xlabel('Day of Year')\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    # Save Plots\n",
    "    plt.savefig(output_file)\n",
    "    plt.close(fig)\n",
    "  \n",
    "# Run plots\n",
    "plot_statistics_mediterranean(start_date_dt, end_date_dt, 'mean', {var: climatology_stats_mediterranean[var]['mean'].mean(dim=['lat', 'lon']) for var in variables if var != 'LSM'}, os.path.join(output_dir, f'mediterranean_climatological_daily_mean_{start_year}_{end_year}.png'))\n",
    "plot_statistics_mediterranean(start_date_dt, end_date_dt, 'std', {var: climatology_stats_mediterranean[var]['std'].mean(dim=['lat', 'lon']) for var in variables if var != 'LSM'}, os.path.join(output_dir, f'mediterranean_climatological_daily_std_{start_year}_{end_year}.png'))\n",
    "plot_statistics_mediterranean(start_date_dt, end_date_dt, 'min', {var: climatology_stats_mediterranean[var]['min'].mean(dim=['lat', 'lon']) for var in variables if var != 'LSM'}, os.path.join(output_dir, f'mediterranean_climatological_daily_min_{start_year}_{end_year}.png'))\n",
    "plot_statistics_mediterranean(start_date_dt, end_date_dt, 'max', {var: climatology_stats_mediterranean[var]['max'].mean(dim=['lat', 'lon']) for var in variables if var != 'LSM'}, os.path.join(output_dir, f'mediterranean_climatological_daily_max_{start_year}_{end_year}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf8175a8-ff14-4f71-a643-6bd4de9aa74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_statistics_mediterranean_with_std(start_date_dt, end_date_dt, stat_name, stat_mean_data, stat_std_data, output_file):\n",
    "    units = {\n",
    "        'T2M': 'K',\n",
    "        'D2M': 'K',\n",
    "        'MSL': 'Pa',\n",
    "        'U10M': 'm/s',\n",
    "        'V10M': 'm/s'\n",
    "    }\n",
    "    fig, axes = plt.subplots(len(units.keys()), 1, figsize=(15, 20), sharex=True)\n",
    "    fig.suptitle(f'Spatially Averaged Climatological Daily {stat_name.capitalize()} over the Mediterranean from {start_date_dt.strftime(\"%Y-%m.%d\")} to {end_date_dt.strftime(\"%Y-%m.%d\")}', fontsize=19)\n",
    "\n",
    "    for i, var in enumerate(units.keys()):\n",
    "        day_range = pd.date_range(start=start_date_dt.replace(day=1).strftime('%Y-%m-%d'), periods=365)\n",
    "        \n",
    "        # Daily Climatology\n",
    "        axes[i].plot(day_range, stat_mean_data[var], label=f'{var} Mean', color='blue')\n",
    "        \n",
    "        # Daily Climatology + std, 2*std, 3*std\n",
    "        axes[i].plot(day_range, stat_mean_data[var] + stat_std_data[var], label=f'{var} Mean + 1*std', color='orange', linestyle='--')\n",
    "        axes[i].plot(day_range, stat_mean_data[var] + 2 * stat_std_data[var], label=f'{var} Mean + 2*std', color='green', linestyle='--')\n",
    "        axes[i].plot(day_range, stat_mean_data[var] + 3 * stat_std_data[var], label=f'{var} Mean + 3*std', color='red', linestyle='--')\n",
    "        \n",
    "        axes[i].set_title(f'{var} {stat_name.capitalize()} with Standard Deviations',fontsize=20)\n",
    "        axes[i].set_ylabel(f'{var} ({units[var]})',fontsize=20)\n",
    "        axes[i].legend(prop={'size': 6})\n",
    "        axes[i].xaxis.set_major_formatter(mdates.DateFormatter('%b'))\n",
    "        axes[i].xaxis.set_major_locator(mdates.MonthLocator())\n",
    "\n",
    "    plt.xlabel('Day of Year')\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    # Save Plots\n",
    "    plt.savefig(output_file)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Run plots\n",
    "plot_statistics_mediterranean_with_std(start_date_dt, end_date_dt,\n",
    "    'mean + std',\n",
    "    {var: climatology_stats_mediterranean[var]['mean'].mean(dim=['lat', 'lon']) for var in variables if var != 'LSM'},\n",
    "    {var: climatology_stats_mediterranean[var]['std'].mean(dim=['lat', 'lon']) for var in variables if var != 'LSM'},\n",
    "    os.path.join(output_dir, f'mediterranean_climatological_daily_mean_with_std_{start_year}_{end_year}.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6260f95d-423d-4dd6-a81f-d39f933217dd",
   "metadata": {},
   "source": [
    "# Checks against climatology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80945759-c27b-43ea-831a-317aa8305deb",
   "metadata": {},
   "source": [
    "The user can set:\n",
    "- start_date, end_date of the period in which he/she wants to check the data\n",
    "- data_dir: directory to the ecmwft .nc data\n",
    "- clim_dir: directory containing the .nc climatology data\n",
    "- output_check_dir: directory of these checks output (can be also the same of output dir of climatology computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68e465a-54eb-4252-b487-2d79f586e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98887a7d-fc21-400f-9e08-3edb1c00893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_range(value, climatology, dayofyear):\n",
    "    \"\"\"Check if the value is within the climatological min and max range, handling np.nan correctly.\"\"\"\n",
    "    #clim_min = climatology['min'].sel(dayofyear=dayofyear)\n",
    "    clim_mean = climatology['mean'].sel(dayofyear=dayofyear)\n",
    "    #clim_max = climatology['max'].sel(dayofyear=dayofyear)\n",
    "    clim_std = climatology['std'].sel(dayofyear=dayofyear)\n",
    "\n",
    "    #nan_mask = np.isnan(value) | np.isnan(clim_min) | np.isnan(clim_max\n",
    "    nan_mask = np.isnan(value) | np.isnan(clim_mean) | np.isnan(clim_std)\n",
    "    #within_range = (value >= clim_min) & (value <= clim_max)\n",
    "    within_range = (value >= clim_mean - 2*clim_std) & (value <= clim_mean + 2*clim_std)\n",
    "\n",
    "    # Apply the NaN mask: where NaN is present, the result should be NaN\n",
    "    within_range = within_range.where(~nan_mask, np.nan)\n",
    "   # Invert the boolean array (transforming 1 into 0, and 0 into 1)\n",
    "    out_of_range = xr.where(within_range == False, 1, 0)\n",
    "\n",
    "    # Ensure NaN values remain unchanged\n",
    "    out_of_range = out_of_range.where(~nan_mask, np.nan)\n",
    "\n",
    "    return out_of_range\n",
    "\n",
    "def check_max(value, climatology, dayofyear):\n",
    "    \"\"\"Check if the value is less than or equal to the climatological max, handling np.nan correctly.\"\"\"\n",
    "    clim_max = climatology['max'].sel(dayofyear=dayofyear)\n",
    "\n",
    "    nan_mask = np.isnan(value) | np.isnan(clim_max)\n",
    "    within_range = np.abs(value) <= np.abs(clim_max)\n",
    "    \n",
    "    # Apply the NaN mask: where NaN is present, the result should be NaN\n",
    "    within_range = within_range.where(~nan_mask, np.nan)\n",
    "   # Invert the boolean array (transforming 1 into 0, and 0 into 1)\n",
    "    out_of_range = xr.where(within_range == False, 1, 0)\n",
    "    \n",
    "    # Ensure NaN values remain unchanged\n",
    "    out_of_range = out_of_range.where(~nan_mask, np.nan)\n",
    "\n",
    "    return out_of_range\n",
    "\n",
    "def check_min(value, climatology, dayofyear):\n",
    "    \"\"\"Check if the value is greater than or equal to the climatological min, handling np.nan correctly.\"\"\"\n",
    "    clim_min = climatology['min'].sel(dayofyear=dayofyear)\n",
    "    \n",
    "    nan_mask = np.isnan(value) | np.isnan(clim_min)\n",
    "    within_range = np.abs(value) <= np.abs(clim_min)\n",
    "    \n",
    "    # Apply the NaN mask: where NaN is present, the result should be NaN\n",
    "    within_range = within_range.where(~nan_mask, np.nan)\n",
    "   # Invert the boolean array (transforming 1 into 0, and 0 into 1)\n",
    "    out_of_range = xr.where(within_range == False, 1, 0)\n",
    "    \n",
    "    # Ensure NaN values remain unchanged\n",
    "    out_of_range = out_of_range.where(~nan_mask, np.nan)\n",
    "\n",
    "    return out_of_range\n",
    "\n",
    "def load_climatology_stats(climatology_dir):\n",
    "    \"\"\"\n",
    "    Load the precomputed climatological statistics.\n",
    "    Here we assume these stats are stored in a format similar to:\n",
    "    climatology_stats['T2M'] = {'mean': ..., 'min': ..., 'max': ..., 'std': ...}\n",
    "    \"\"\"\n",
    "    climatology_stats = {}\n",
    "    variables = ['T2M', 'D2M', 'MSL', 'U10M', 'V10M', 'LSM']\n",
    "    \n",
    "    for var in variables:\n",
    "        ds = xr.open_dataset(os.path.join(climatology_dir, f'{var}_climatology_mediterranean.nc'))\n",
    "        climatology_stats[var] = {\n",
    "            'mean': ds['mean'],\n",
    "            'min': ds['min'],\n",
    "            'max': ds['max'],\n",
    "            'std': ds['std']\n",
    "        }\n",
    "    \n",
    "    return climatology_stats\n",
    "\n",
    "def align_to_climatology(ds, climatology_stats):\n",
    "    \"\"\"\n",
    "    Align the spatial domain of 'ds' to the lat/lon range of the climatology_stats.\n",
    "    \n",
    "    Parameters:\n",
    "    - ds: xarray.Dataset, the dataset to align\n",
    "    - climatology_stats: dict, the precomputed climatology statistics\n",
    "\n",
    "    Returns:\n",
    "    - ds_aligned: xarray.Dataset, the dataset aligned to the climatology spatial domain\n",
    "    \"\"\"\n",
    "    # Extract the lat/lon ranges from the climatology LSM mask\n",
    "    lat_range = climatology_stats['LSM']['mean']['lat']\n",
    "    lon_range = climatology_stats['LSM']['mean']['lon']\n",
    "    \n",
    "    # Slice ds to match the climatology lat/lon ranges\n",
    "    ds_aligned = ds.sel(lat=slice(lat_range.max(), lat_range.min()), lon=slice(lon_range.min(), lon_range.max()))\n",
    "    ds_aligned = ds_aligned.where(~np.isnan(climatology_stats['LSM']['mean'][0]), np.nan)\n",
    "    \n",
    "    return ds_aligned\n",
    "\n",
    "def extract_anomalies(ds, alerts, date, output_plot_dir):\n",
    "    \"\"\"Extract anomalies based on alerts for a specific date.\"\"\"\n",
    "    anomalies = {}\n",
    "    \n",
    "    var_mapping = {\n",
    "        'T2M_mean_alert': 'T2M',\n",
    "        'D2M_mean_alert': 'D2M',\n",
    "        'MSL_mean_alert': 'MSL',\n",
    "        'U10M_mean_alert': 'U10M',\n",
    "        'V10M_mean_alert': 'V10M',\n",
    "        'U10M_max_alert': 'U10M',\n",
    "        'U10M_min_alert': 'U10M',\n",
    "        'V10M_max_alert': 'V10M',\n",
    "        'V10M_min_alert': 'V10M'\n",
    "    }\n",
    "\n",
    "    latitudes = ds['lat'].values\n",
    "    longitudes = ds['lon'].values\n",
    "    \n",
    "    # Create subfolder for the date\n",
    "    day_dir = os.path.join(output_plot_dir, date.strftime('%Y-%m-%d'))\n",
    "    os.makedirs(day_dir, exist_ok=True)\n",
    "    \n",
    "    for var, alert in alerts.items():\n",
    "        if isinstance(alert, xr.DataArray):\n",
    "            if var in var_mapping:\n",
    "                data_var = var_mapping[var]\n",
    "                print(\"plot alert map\")\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                alert.plot()\n",
    "                print(\"save\")\n",
    "                plt.savefig(f\"{day_dir}/alert_map_{var}_{date.strftime('%Y-%m-%d')}\")\n",
    "                plt.close()\n",
    "            else:\n",
    "                continue\n",
    "            alert_values = alert.values\n",
    "            # Find alert indices inside the domain\n",
    "            alert_indices = np.argwhere(alert_values == 1)\n",
    "            \n",
    "            if len(alert_indices) > 0:\n",
    "                lat_alerts = latitudes[alert_indices[:, 0]]\n",
    "                lon_alerts = longitudes[alert_indices[:, 1]]\n",
    "                \n",
    "                values_alerts = np.array([\n",
    "                    ds[data_var].sel(lat=latitudes[lat_idx], lon=longitudes[lon_idx]).values\n",
    "                    for lat_idx, lon_idx in alert_indices\n",
    "                ])\n",
    "                \n",
    "                anomalies[var] = {\n",
    "                    'latitude': lat_alerts,\n",
    "                    'longitude': lon_alerts,\n",
    "                    'values': values_alerts\n",
    "                }\n",
    "    \n",
    "    return anomalies\n",
    "\n",
    "def generate_alert_plots(date, ds, climatology_stats, alerts, dayofyear, output_plot_dir):\n",
    "    \"\"\"Generate and save plots for variables with alert and create CSV files.\"\"\"\n",
    "    variable_map = {\n",
    "        'T2M_mean_alert': 'T2M',\n",
    "        'D2M_mean_alert': 'D2M',\n",
    "        'MSL_mean_alert': 'MSL',\n",
    "        'U10M_mean_alert': 'U10M',\n",
    "        'V10M_mean_alert': 'V10M',\n",
    "        'U10M_max_alert': 'U10M',\n",
    "        'V10M_max_alert': 'V10M',\n",
    "        'U10M_min_alert': 'U10M',\n",
    "        'V10M_min_alert': 'V10M',\n",
    "    }\n",
    "\n",
    "    anomalies = extract_anomalies(ds, alerts, date, output_plot_dir)\n",
    "    \n",
    "    day_dir = os.path.join(output_plot_dir, date.strftime('%Y-%m-%d'))\n",
    "    os.makedirs(day_dir, exist_ok=True)\n",
    "    \n",
    "    for alert_var, anomaly_data in anomalies.items():\n",
    "        var = variable_map.get(alert_var)\n",
    "        if var is None:\n",
    "            print(f\"No mapping found for alert variable: {alert_var}\")\n",
    "            continue\n",
    "        \n",
    "        # Create CSV file\n",
    "        csv_data = []\n",
    "        csv_data_uv = []\n",
    "        for lat, lon, value in zip(anomaly_data['latitude'], anomaly_data['longitude'], anomaly_data['values']):\n",
    "            if var in ['T2M', 'D2M', 'MSL','U10M','V10M']:\n",
    "                # Compute mean of values_alerts\n",
    "                value_mean = value.mean()\n",
    "                clim_max = climatology_stats[var]['max'].sel(dayofyear=dayofyear, lat=lat, lon=lon, method='nearest').values\n",
    "                clim_mean = climatology_stats[var]['mean'].sel(dayofyear=dayofyear, lat=lat, lon=lon, method='nearest').values\n",
    "                clim_min = climatology_stats[var]['min'].sel(dayofyear=dayofyear, lat=lat, lon=lon, method='nearest').values\n",
    "                \n",
    "                csv_data.append([lat, lon, value, value_mean, clim_min, clim_mean, clim_max])\n",
    "            \n",
    "            elif var in ['U10M', 'V10M']:\n",
    "                # Compute max and min of values_alerts\n",
    "                value_max = value.max()\n",
    "                value_min = value.min()\n",
    "                clim_max = climatology_stats[var]['max'].sel(dayofyear=dayofyear, lat=lat, lon=lon, method='nearest').values\n",
    "                clim_min = climatology_stats[var]['min'].sel(dayofyear=dayofyear, lat=lat, lon=lon, method='nearest').values\n",
    "                \n",
    "                csv_data_uv.append([lat, lon, value, value_max, clim_max, value_min, clim_min])\n",
    "        \n",
    "        if var in ['T2M', 'D2M', 'MSL','U10M','V10M']:\n",
    "            csv_columns = ['lat_alerts', 'lon_alerts', 'values_alerts', 'mean_value', 'climatology_min', 'climatology_mean' ,'climatology_max']\n",
    "        elif var in ['U10M', 'V10M']:\n",
    "            csv_columns = ['lat_alerts', 'lon_alerts', 'values_alerts', 'max_value', 'climatology_max', 'min_value', 'climatology_min']\n",
    "        \n",
    "        # Save CSV files\n",
    "        csv_path = os.path.join(day_dir, f'{var}_anomalies_{date.strftime(\"%Y%m%d\")}.csv')\n",
    "        df = pd.DataFrame(csv_data, columns=csv_columns)\n",
    "        df.to_csv(csv_path, index=False)\n",
    "\n",
    "        csv_uv_path = os.path.join(day_dir, f'{var}_anomalies_{date.strftime(\"%Y%m%d\")}.csv')\n",
    "        df = pd.DataFrame(csv_data_uv, columns=csv_columns)\n",
    "        df.to_csv(csv_uv_path, index=False)       \n",
    "\n",
    "def calculate_time_series(climatology_stats, start_date, end_date, date_range, data_dir):\n",
    "    \"\"\"\n",
    "    Compute time series for variables T2M, D2M, MSL, U10M e V10M and for the corresponding climatological time series\n",
    "    \"\"\"\n",
    "    \n",
    "    time_series = {\n",
    "        'T2M': [],\n",
    "        'D2M': [],\n",
    "        'MSL': [],\n",
    "        'LSM': [],\n",
    "        'U10M': [],\n",
    "        'V10M': [],\n",
    "        'U10M_max': [],\n",
    "        'U10M_min': [],\n",
    "        'V10M_max': [],\n",
    "        'V10M_min': []\n",
    "    }\n",
    "    \n",
    "    clim_series = {\n",
    "        'T2M': {'mean': [], 'max': [], 'min': [], 'std': []},\n",
    "        'D2M': {'mean': [], 'max': [], 'min': [], 'std': []},\n",
    "        'MSL': {'mean': [], 'max': [], 'min': [], 'std': []},\n",
    "        'U10M': {'mean': [], 'max': [], 'min': [], 'std': []},\n",
    "        'V10M': {'mean': [], 'max': [], 'min': [], 'std': []}\n",
    "    }\n",
    "    \n",
    "    for date in date_range:\n",
    "        print(date)\n",
    "        year, month, day = date.year, date.month, date.day\n",
    "        file_pattern = os.path.join(data_dir, f'{year}/{month:02d}', f'*{year:02d}{month:02d}{day:02d}*MEDATL*.nc')\n",
    "        files = sorted(glob.glob(file_pattern))\n",
    "        \n",
    "        if not files:\n",
    "            print(f\"No files found for {date}\")\n",
    "            continue\n",
    "        \n",
    "        for file in files:\n",
    "            print(file)\n",
    "            print(\"apri file\")\n",
    "            ds = xr.open_dataset(file)\n",
    "            \n",
    "        # Align ds to the climatology domain\n",
    "        ds_aligned = align_to_climatology(ds, climatology_stats)\n",
    "        ds_day = ds_aligned\n",
    "        \n",
    "        daily_mean = ds_day[['T2M', 'D2M', 'MSL','U10M','V10M']].mean(dim=['lat', 'lon'])\n",
    "        daily_max = ds_day[['U10M', 'V10M']].max(dim=['time']).mean(dim=['lat', 'lon'])\n",
    "        daily_min = ds_day[['U10M', 'V10M']].min(dim=['time']).mean(dim=['lat', 'lon'])\n",
    "        daily_sum = ds_day[['LSM']].where(ds_day['LSM'] != False, 1).sum(dim=['lat', 'lon'])\n",
    "        \n",
    "        time_series['T2M'].append(daily_mean['T2M'].values)\n",
    "        time_series['D2M'].append(daily_mean['D2M'].values)\n",
    "        time_series['MSL'].append(daily_mean['MSL'].values)\n",
    "        time_series['LSM'].append(daily_sum['LSM'].values)\n",
    "        time_series['U10M'].append(daily_mean['U10M'].values)\n",
    "        time_series['V10M'].append(daily_mean['V10M'].values)\n",
    "        time_series['U10M_max'].append(daily_max['U10M'].values)\n",
    "        time_series['U10M_min'].append(daily_min['U10M'].values)\n",
    "        time_series['V10M_max'].append(daily_max['V10M'].values)\n",
    "        time_series['V10M_min'].append(daily_min['V10M'].values)\n",
    "    \n",
    "    for var in ['T2M', 'D2M', 'MSL', 'U10M', 'V10M']:\n",
    "        clim_mean = climatology_stats[var]['mean'].mean(dim=['lat', 'lon'])\n",
    "        clim_max = climatology_stats[var]['max'].mean(dim=['lat', 'lon'])\n",
    "        clim_min = climatology_stats[var]['min'].mean(dim=['lat', 'lon'])\n",
    "        clim_std = climatology_stats[var]['std'].mean(dim=['lat', 'lon'])\n",
    "        # Repeat climatological series for the number of years in the range if needed\n",
    "\n",
    "        if (datetime.strptime(end_date, '%Y-%m-%d') - datetime.strptime(start_date, '%Y-%m-%d')).days > 365:\n",
    "            years = (datetime.strptime(end_date, '%Y-%m-%d') - datetime.strptime(start_date, '%Y-%m-%d')).days // 365 + 1\n",
    "            clim_mean = clim_mean.expand_dims(dim='time').broadcast_like(clim_mean, exclude={dim: years for dim in clim_mean.dims})\n",
    "            clim_max = clim_max.expand_dims(dim='time').broadcast_like(clim_max, exclude={dim: years for dim in clim_max.dims})\n",
    "            clim_min = clim_min.expand_dims(dim='time').broadcast_like(clim_min, exclude={dim: years for dim in clim_min.dims})\n",
    "            clim_std = clim_std.expand_dims(dim='time').broadcast_like(clim_std, exclude={dim: years for dim in clim_std.dims})\n",
    "\n",
    "        clim_series[var]['mean'] = clim_mean\n",
    "        clim_series[var]['max'] = clim_max\n",
    "        clim_series[var]['min'] = clim_min\n",
    "        clim_series[var]['std'] = clim_std\n",
    "    \n",
    "    for var in ['U10M', 'V10M']:\n",
    "        clim_max = climatology_stats[var]['max'].mean(dim=['lat', 'lon'])\n",
    "        clim_min = climatology_stats[var]['min'].mean(dim=['lat', 'lon'])\n",
    "        # Repeat climatological series for the number of years in the range if needed\n",
    "        if (datetime.strptime(end_date, '%Y-%m-%d') - datetime.strptime(start_date, '%Y-%m-%d')).days > 365:\n",
    "            years = (datetime.strptime(end_date, '%Y-%m-%d') - datetime.strptime(start_date, '%Y-%m-%d')).days // 365 + 1\n",
    "            clim_max = clim_max.expand_dims(dim='time').broadcast_like(clim_max, {dim: years for dim in clim_max.dims})\n",
    "            clim_min = clim_min.expand_dims(dim='time').broadcast_like(clim_min, {dim: years for dim in clim_min.dims})\n",
    "        \n",
    "        clim_series[var]['max'] = clim_max\n",
    "        clim_series[var]['min'] = clim_min\n",
    "\n",
    "    \n",
    "    return time_series, clim_series, ds_day\n",
    "\n",
    "def plot_time_series(time_series, clim_series, start_date, end_date, date_range, date_range_4h, output_dir):\n",
    "    \"\"\"\n",
    "    Create and save plots of time series for specified variable.\n",
    "    \"\"\"\n",
    "    variable_map = {\n",
    "        'U10M_max': 'U10M',\n",
    "        'V10M_max': 'V10M',\n",
    "        'U10M_min': 'U10M',\n",
    "        'V10M_min': 'V10M',\n",
    "    }\n",
    "    \n",
    "    start_year = datetime.strptime(start_date, '%Y-%m-%d').year\n",
    "    end_year = datetime.strptime(end_date, '%Y-%m-%d').year\n",
    "    \n",
    "    # Creiamo una data range per l'anno climatologico di riferimento (es. 2020)\n",
    "    climatology_dates = pd.date_range(start=f'{start_year}-01-01', end=f'{start_year}-12-31', freq='D')\n",
    "    # Rimuovere il 29 febbraio se esiste\n",
    "    climatology_dates = climatology_dates[~((climatology_dates.month == 2) & (climatology_dates.day == 29))]    \n",
    "    \n",
    "    for var in time_series:\n",
    "        os.makedirs(os.path.join(output_dir, f'{var}'), exist_ok=True)\n",
    "        print(os.path.join(output_dir, f'{var}'))\n",
    "        if var in ['T2M', 'D2M', 'MSL', 'U10M', 'V10M']:\n",
    "            \n",
    "            # Se l'intervallo copre più di un anno, ripetiamo la serie climatologica per tutti gli anni necessari\n",
    "            if end_year > start_year:\n",
    "                extended_dates = pd.date_range(start=f'{start_year}-01-01', end=f'{end_year}-12-31', freq='D')\n",
    "                extended_dates = extended_dates[~((extended_dates.month == 2) & (extended_dates.day == 29))]  # Rimuovere eventuali 29 febbraio\n",
    "                climatology_values_mean = np.tile(clim_series[var]['mean'].values, len(extended_dates) // 365)[0]\n",
    "                climatology_values_std = np.tile(clim_series[var]['std'].values, len(extended_dates) // 365)[0]\n",
    "                climatology_values_max = np.tile(clim_series[var]['max'].values, len(extended_dates) // 365)[0]\n",
    "                climatology_values_min = np.tile(clim_series[var]['min'].values, len(extended_dates) // 365)[0]\n",
    "            else:\n",
    "                extended_dates = climatology_dates\n",
    "                climatology_values_std = clim_series[var]['std'].values\n",
    "                climatology_values_mean = clim_series[var]['mean'].values\n",
    "                climatology_values_max = clim_series[var]['max'].values\n",
    "                climatology_values_min = clim_series[var]['min'].values\n",
    "                \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.plot(date_range_4h, np.concatenate(time_series[var]), label=f'{var} observed', color='blue')\n",
    "            plt.plot(extended_dates, climatology_values_mean, label=f'{var} climatological mean', color='red', linestyle='--')\n",
    "            plt.plot(extended_dates, climatology_values_max, label=f'{var} climatological max', color='green', linestyle='--')\n",
    "            plt.plot(extended_dates, climatology_values_min, label=f'{var} climatological min', color='orange', linestyle='--')\n",
    "            \n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel(f'{var}')\n",
    "            plt.title(f'{var} Time Series Comparison With Climatology')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            # Save the plot\n",
    "            plot_path = os.path.join(output_dir, f'{var}/{var}_time_series_{start_date}_{end_date}.png')\n",
    "            plt.savefig(plot_path)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.plot(date_range, np.array([np.mean(arr) for arr in time_series[var]]), label=f'{var} observed', color='blue')\n",
    "            plt.plot(extended_dates, climatology_values_mean, label=f'{var} climatological mean', color='red', linestyle='--')\n",
    "            plt.fill_between(extended_dates, climatology_values_min, climatology_values_max, color='blue',alpha=0.2)\n",
    "            \n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel(f'{var}')\n",
    "            plt.title(f'{var} Time Series Comparison With Climatology')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            # Save the plot\n",
    "            plot_path = os.path.join(output_dir, f'{var}/{var}_time_series_{start_date}_{end_date}_daily_shaded_area.png')\n",
    "            plt.savefig(plot_path)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.plot(date_range, np.array([np.mean(arr) for arr in time_series[var]]), label=f'{var} observed', color='blue')\n",
    "            plt.plot(extended_dates, climatology_values_mean, label=f'{var} climatological mean', color='red', linestyle='--')\n",
    "\n",
    "            plt.fill_between(extended_dates, climatology_values_mean - 2*climatology_values_std, climatology_values_mean + 2*climatology_values_std, color='blue',alpha=0.2)\n",
    "            \n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel(f'{var}')\n",
    "            plt.title(f'{var} Time Series Comparison With Climatology')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            # Save the plot\n",
    "            plot_path = os.path.join(output_dir, f'{var}/{var}_time_series_{start_date}_{end_date}_daily_mean_std_shaded_area.png')\n",
    "            plt.savefig(plot_path)\n",
    "            plt.close()\n",
    "            \n",
    "        if var in ['U10M_max', 'U10M_min', 'V10M_max', 'V10M_min']:\n",
    "            clim_var = variable_map.get(var)\n",
    "            # Se l'intervallo copre più di un anno, ripetiamo la serie climatologica per tutti gli anni necessari\n",
    "            if end_year > start_year:\n",
    "                extended_dates = pd.date_range(start=f'{start_year}-01-01', end=f'{end_year}-12-31', freq='D')\n",
    "                extended_dates = extended_dates[~((extended_dates.month == 2) & (extended_dates.day == 29))]  # Rimuovere eventuali 29 febbraio\n",
    "                climatology_values_max = np.tile(clim_series[clim_var]['max'].values, len(extended_dates) // 365)[0]\n",
    "                climatology_values_min = np.tile(clim_series[clim_var]['min'].values, len(extended_dates) // 365)[0]\n",
    "            else:\n",
    "                extended_dates = climatology_dates\n",
    "                climatology_values_max = clim_series[clim_var]['max'].values\n",
    "                climatology_values_min = clim_series[clim_var]['min'].values\n",
    "            if var in ['U10M_max', 'V10M_max']:\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                plt.plot(date_range, time_series[var], label=f'{var} observed', color='blue')\n",
    "                plt.plot(extended_dates, climatology_values_max, label=f'{var} climatological max', color='green', linestyle='--')\n",
    "                plt.xlabel('Date')\n",
    "                plt.ylabel(f'{var}')\n",
    "                plt.title(f'{var} Max Time Series Comparison With Climatology')\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "            \n",
    "                # Save the plot\n",
    "                plot_path = os.path.join(output_dir, f'{var}/{var}_time_series_{start_date}_{end_date}.png')\n",
    "                plt.savefig(plot_path)\n",
    "                plt.close()\n",
    "            if var in ['U10M_min', 'V10M_min']:\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                plt.plot(date_range, time_series[var], label=f'{var} observed', color='blue')\n",
    "                plt.plot(extended_dates, climatology_values_min, label=f'{var} climatological min', color='orange', linestyle='--')\n",
    "                plt.xlabel('Date')\n",
    "                plt.ylabel(f'{var}')\n",
    "                plt.title(f'{var} Min Time Series Comparison With Climatology')\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "            \n",
    "                # Save the plot\n",
    "                plot_path = os.path.join(output_dir, f'{var}/{var}_time_series_{start_date}_{end_date}.png')\n",
    "                plt.savefig(plot_path)\n",
    "                plt.close()\n",
    "        if var in ['LSM']:\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.plot(date_range_4h, np.concatenate(time_series[var]), label=f'{var} observed', color='blue')\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel(f'{var} sum')\n",
    "            plt.title(f'{var} Sum Time Series')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "        \n",
    "            # Save the plot\n",
    "            plot_path = os.path.join(output_dir, f'{var}/{var}_sum_time_series_{start_date}_{end_date}.png')\n",
    "            plt.savefig(plot_path)\n",
    "            plt.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "990dda38-ff7f-4973-aca0-1a2d828008a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='/data/inputs/METOCEAN/historical/model/atmos/ECMWF/IFS_010/analysis/6h/netcdf/'\n",
    "climatology_dir='/work/cmcc/mg28621/out_ECMWF_Tool_Checks/'\n",
    "output_plot_dir='/work/cmcc/mg28621/out_ECMWF_Tool_Checks/output_checks/'\n",
    "start_date='2024-01-01'\n",
    "end_date='2024-07-31'\n",
    "\n",
    "limite_dict = {'T2M':10,'D2M':10,'MSL':2500,'U10M':15,'V10M':15}\n",
    "uom_dict = {'T2M':'K','D2M':'K/°C','MSL':'Pa','U10M':'m/s','V10M':'m/s'}\n",
    "\n",
    "if end_date is None:\n",
    "    end_date = start_date\n",
    "\n",
    "# Load climatological statistics (precomputed)\n",
    "climatology_stats = load_climatology_stats(climatology_dir)\n",
    "\n",
    "# Itera su ciascun parametro ('T2M', 'D2M', etc.)\n",
    "for param in climatology_stats:\n",
    "    # Prendi la maschera LSM per il parametro corrente\n",
    "    lsm_mask = climatology_stats['LSM']['mean']\n",
    "    \n",
    "    # Itera su ciascun tipo di statistica ('mean', 'min', 'max', etc.)\n",
    "    for stat in climatology_stats[param]:\n",
    "        # Applica la maschera: imposta NaN dove LSM è 1\n",
    "        climatology_stats[param][stat] = climatology_stats[param][stat].where(lsm_mask != 1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c56255-a13c-4b31-9fbf-906193e11a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_plot_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each date in the specified range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "mask = ~((date_range.month == 2) & (date_range.day == 29))\n",
    "date_range = date_range[mask]\n",
    "\n",
    "date_range_4h = pd.date_range(start=start_date, end=end_date, freq='6h')\n",
    "last_day = pd.to_datetime(end_date).normalize()\n",
    "last_day_hours = pd.date_range(start=last_day, end=last_day + pd.Timedelta(hours=18), freq='6h')\n",
    "# Aggiungi gli orari mancanti solo se non sono già inclusi\n",
    "date_range_4h = date_range_4h.union(last_day_hours)\n",
    "mask = ~((date_range_4h.month == 2) & (date_range_4h.day == 29))\n",
    "date_range_4h = date_range_4h[mask]\n",
    "\n",
    "# Calculate time series\n",
    "time_series, clim_series, ds_day = calculate_time_series(climatology_stats, start_date, end_date, date_range, data_dir)\n",
    "\n",
    "# Generate and save time series plots\n",
    "plot_time_series(time_series, clim_series, start_date, end_date, date_range, date_range_4h, output_plot_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "082d6548-682c-4f1e-b737-6a13e1f2f876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1449dfb8-a7f5-48fb-83e2-8f692ac6bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = datetime.strptime(start_date, '%Y-%m-%d').year\n",
    "end_year = datetime.strptime(end_date, '%Y-%m-%d').year\n",
    "# Creiamo una data range per l'anno climatologico di riferimento (es. 2020)\n",
    "climatology_dates = pd.date_range(start=f'{start_year}-01-01', end=f'{start_year}-12-31', freq='D')\n",
    "# Rimuovere il 29 febbraio se esiste\n",
    "climatology_dates = climatology_dates[~((climatology_dates.month == 2) & (climatology_dates.day == 29))]\n",
    "\n",
    "day_time=['00','06','12','18']\n",
    "\n",
    "for var in time_series:\n",
    "    print(var)\n",
    "    if var in ['T2M', 'D2M', 'MSL', 'U10M', 'V10M']:\n",
    "    #if var in ['T2M']:\n",
    "        # Se l'intervallo copre più di un anno, ripetiamo la serie climatologica per tutti gli anni necessari\n",
    "        if end_year > start_year:\n",
    "            extended_dates = pd.date_range(start=f'{start_year}-01-01', end=f'{end_year}-12-31', freq='D')\n",
    "            extended_dates = extended_dates[~((extended_dates.month == 2) & (extended_dates.day == 29))]  # Rimuovere eventuali 29 febbraio\n",
    "            climatology_values_mean = np.tile(clim_series[var]['mean'].values, len(extended_dates) // 365)[0]\n",
    "            climatology_values_std = np.tile(clim_series[var]['std'].values, len(extended_dates) // 365)[0]\n",
    "            climatology_values_max = np.tile(clim_series[var]['max'].values, len(extended_dates) // 365)[0]\n",
    "            climatology_values_min = np.tile(clim_series[var]['min'].values, len(extended_dates) // 365)[0]\n",
    "        else:\n",
    "            extended_dates = climatology_dates\n",
    "            climatology_values_std = clim_series[var]['std'].values\n",
    "            climatology_values_mean = clim_series[var]['mean'].values\n",
    "            climatology_values_max = clim_series[var]['max'].values\n",
    "            climatology_values_min = clim_series[var]['min'].values\n",
    "            \n",
    "        observed_values = np.array([np.mean(arr) for arr in time_series[var]])\n",
    "        upper_bound = climatology_values_mean + 2 * climatology_values_std\n",
    "        lower_bound = climatology_values_mean - 2 * climatology_values_std\n",
    "\n",
    "        # Identify indices where conditions are satisfied (range exceeded)\n",
    "        exceeding_indices = np.where((observed_values > upper_bound[:len(observed_values)]) | (observed_values < lower_bound[:len(observed_values)]))[0]\n",
    "        \n",
    "        # Get corresponding days\n",
    "        exceeding_days = date_range[exceeding_indices]\n",
    "        print(f\"The days that exceed the range limits for {var} are: {exceeding_days}\")\n",
    "\n",
    "        for day in exceeding_days:\n",
    "            \n",
    "            # Load climatological dataset for specific day\n",
    "            climatology_data = climatology_stats[var]['mean'][day.dayofyear - 1]  # -1 per indice zero-based\n",
    "            \n",
    "            year, month, day_i = day.year, day.month, day.day\n",
    "            dayofyear = day.timetuple().tm_yday\n",
    "        \n",
    "            file_pattern = os.path.join(data_dir, f'{year}/{month:02d}', f'*{year:02d}{month:02d}{day_i:02d}*MEDATL*.nc')\n",
    "            files = sorted(glob.glob(file_pattern))  # Usa glob per trovare i file corrispondenti\n",
    "        \n",
    "            if not files:\n",
    "                print(f\"No files found for the day {day.strftime('%Y-%m-%d')}\")\n",
    "                continue\n",
    "        \n",
    "            ds = xr.open_dataset(files[0])\n",
    "            ds_aligned = align_to_climatology(ds, climatology_stats)\n",
    "            observation_data_tot = ds_aligned[var]\n",
    "            \n",
    "            daily_mean = ds_aligned[[var]].mean(dim='time')\n",
    "            \n",
    "            # Calculate daily max and min for U10M and V10M\n",
    "            if var in ['U10M','V10M']:\n",
    "                daily_max = ds_aligned[var].max(dim='time')\n",
    "                daily_min = ds_aligned[var].min(dim='time')\n",
    "            \n",
    "            \n",
    "            # Perform checks against climatology\n",
    "            print(\"perform checks against climatology\")\n",
    "    \n",
    "            alerts = {\n",
    "                'date': day.strftime('%Y-%m-%d'),\n",
    "                f'{var}_mean_alert': check_range(daily_mean[var], climatology_stats[var], dayofyear)\n",
    "            }\n",
    "\n",
    "            if var in ['U10M','V10M']:\n",
    "                alerts.update({\n",
    "                        f'{var}_min_alert': check_min(daily_min[var], climatology_stats[var], dayofyear),\n",
    "                        f'{var}_max_alert': check_max(daily_max[var], climatology_stats[var], dayofyear)\n",
    "                    })\n",
    "\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(10, 5), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "            ticks = np.linspace(min(observation_data_tot.min(),climatology_data.min()),max(observation_data_tot.max(),climatology_data.max()),5,endpoint=True)\n",
    "            climatology_data.plot(ax=ax, cmap='coolwarm', transform=ccrs.PlateCarree(), vmin=min(observation_data_tot.min(),climatology_data.min()), vmax=max(observation_data_tot.max(),climatology_data.max()), cbar_kwargs={'shrink': 0.7, 'aspect': 30, 'pad': 0.15, 'ticks': ticks})\n",
    "            \n",
    "            plt.title(f\"{var} Climatology for day {day.strftime('%Y-%m-%d')}\", fontsize=20)\n",
    "            \n",
    "            ax.add_feature(cfeature.LAND, facecolor='grey')\n",
    "            ax.coastlines()\n",
    "            ax.gridlines(draw_labels=True)\n",
    "            climatology_plot_path = os.path.join(output_plot_dir, f\"{var}/climatology_{var}_{day.strftime('%Y%m%d')}.png\")\n",
    "            plt.savefig(climatology_plot_path)\n",
    "            plt.close()\n",
    "\n",
    "            norm = TwoSlopeNorm(vmin=-limite_dict[var], vcenter=0, vmax=limite_dict[var])\n",
    "            ticks = np.linspace(-limite_dict[var],limite_dict[var],5,endpoint=True)\n",
    "            fig, ax = plt.subplots(figsize=(10, 5), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "            (daily_mean[var]-climatology_data).where(alerts[f'{var}_mean_alert']).plot(ax=ax, cmap='coolwarm', transform=ccrs.PlateCarree(),norm=norm, cbar_kwargs={'shrink': 0.7, 'aspect': 30, 'pad': 0.15, 'ticks': ticks, 'label': 'bias'})\n",
    "            \n",
    "            plt.title(f\"{var} Differences in exceeding grid points for day {day.strftime('%Y-%m-%d')}\", fontsize=14)\n",
    "            \n",
    "            ax.add_feature(cfeature.LAND, facecolor='grey')\n",
    "            ax.coastlines()\n",
    "            ax.gridlines(draw_labels=True)\n",
    "            exceeding_differences_plot_path = os.path.join(output_plot_dir, f\"{var}/exceeding_differences_{var}_{day.strftime('%Y%m%d')}.png\")\n",
    "            plt.savefig(exceeding_differences_plot_path)\n",
    "            plt.close()\n",
    "\n",
    "            fig, axs = plt.subplots(2, 2, figsize=(10, 5), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "            fig.suptitle(f\"{var} ECMWF data for the day {day.strftime('%Y-%m-%d')}\", fontsize=15)\n",
    "\n",
    "            norm = TwoSlopeNorm(vmin=min(observation_data_tot.min(),climatology_data.min()), vcenter= (min(observation_data_tot.min(),climatology_data.min())+max(observation_data_tot.max(),climatology_data.max()))/2, vmax=max(observation_data_tot.max(),climatology_data.max()))\n",
    "            ticks = np.linspace(min(observation_data_tot.min(),climatology_data.min()),max(observation_data_tot.max(),climatology_data.max()),5,endpoint=True)\n",
    "            \n",
    "            for i,time_step in enumerate(range(len(ds.time))):\n",
    "                # Load observations for the variable at the 4 time steps of the day\n",
    "                observation_data = ds_aligned[var].isel(time=time_step)\n",
    "                \n",
    "                row, col = divmod(time_step, 2)\n",
    "                ax = axs[row, col]\n",
    "                \n",
    "                observation_data.plot(ax=ax, cmap='coolwarm', transform=ccrs.PlateCarree(),norm=norm,add_colorbar=False)\n",
    "                ax.set_title(f\"{day_time[i]}\",fontsize=10)\n",
    "                \n",
    "                ax.add_feature(cfeature.LAND, facecolor='grey')\n",
    "                ax.coastlines()\n",
    "                ax.gridlines(draw_labels=True)\n",
    "\n",
    "            # Creare una singola colorbar in basso\n",
    "            plt.subplots_adjust(hspace=0.6, wspace=0.6)\n",
    "            sm = plt.cm.ScalarMappable(cmap='coolwarm', norm=norm)\n",
    "            sm.set_array([])\n",
    "            cbar = fig.colorbar(sm, ax=axs, orientation='horizontal', shrink=0.4, aspect=30, pad=0.1, ticks=ticks)\n",
    "            cbar.set_label(f'Obs ({uom_dict[var]})')\n",
    "\n",
    "            observation_plot_path = os.path.join(output_plot_dir, f\"{var}/observations_{var}_{day.strftime('%Y%m%d')}.png\")\n",
    "            plt.savefig(observation_plot_path)\n",
    "            plt.close()\n",
    "\n",
    "            fig, axs = plt.subplots(2, 2, figsize=(10, 5), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "            fig.suptitle(f\"{var} Differences Data-Clim for the day {day.strftime('%Y-%m-%d')}\",fontsize=15)\n",
    "\n",
    "            norm = TwoSlopeNorm(vmin=-limite_dict[var], vcenter=0, vmax=limite_dict[var])\n",
    "            ticks = np.linspace(-limite_dict[var],limite_dict[var],5,endpoint=True)\n",
    "            \n",
    "            for i,time_step in enumerate(range(len(ds.time))):\n",
    "                # Load observations for the variable at the 4 time steps of the day\n",
    "                observation_data = ds_aligned[var].isel(time=time_step)\n",
    "                \n",
    "                row, col = divmod(time_step, 2)\n",
    "                ax = axs[row, col]\n",
    "                \n",
    "                (observation_data-climatology_data).plot(ax=ax, transform=ccrs.PlateCarree(), cmap='RdBu_r',norm=norm,add_colorbar=False)\n",
    "        \n",
    "                \n",
    "                \n",
    "                ax.set_title(f\"{day_time[i]}\",fontsize=10)\n",
    "                \n",
    "                ax.add_feature(cfeature.LAND, facecolor='grey')\n",
    "                ax.coastlines()\n",
    "                ax.gridlines(draw_labels=True)\n",
    "            # Creare una singola colorbar in basso\n",
    "            plt.subplots_adjust(hspace=0.6, wspace=0.6)\n",
    "            sm = plt.cm.ScalarMappable(cmap='RdBu_r', norm=norm)\n",
    "            sm.set_array([])\n",
    "            cbar = fig.colorbar(sm, ax=axs, orientation='horizontal', shrink=0.4, aspect=30, pad=0.1, ticks=ticks)\n",
    "            cbar.set_label(f'Differences Obs-Clim ({uom_dict[var]})')\n",
    "\n",
    "            differences_plot_path = os.path.join(output_plot_dir, f\"{var}/differences_{var}_{day.strftime('%Y%m%d')}.png\")\n",
    "            plt.savefig(differences_plot_path)\n",
    "            plt.close()\n",
    "    else:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval_rean",
   "language": "python",
   "name": "eval_rean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
